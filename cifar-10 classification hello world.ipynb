{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification on set of images with a 10 different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_final_history(history):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "    ax[0].set_title('loss')\n",
    "    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "    ax[1].set_title('acc')\n",
    "    ax[1].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n",
    "    ax[1].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cifar 10 has the dimensions of 32x32x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#image constants\n",
    "\n",
    "img_channels = 3\n",
    "image_row = 32\n",
    "image_col = 32\n",
    "\n",
    "#constants for util\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_class = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check whether all of the images loaded from the dataset hav the right shape and type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To get started with the training and test suprivsed labels will need to be change into categorical values while also changing array to floats for numeric operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to catorgies \n",
    "y_train = np_utils.to_categorical(y_train, NB_class)\n",
    "y_test = np_utils.to_categorical(y_test, NB_class)\n",
    "\n",
    "\n",
    "#normalise and change type to float\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /=255\n",
    "x_test /=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,200,842\n",
      "Trainable params: 4,200,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "  model = Sequential()\n",
    "  \n",
    "model.add(Conv2D(32, (3,3), padding = 'same', input_shape=(32,32,3)))\n",
    " \n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10))\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#removal of metric accuracy due to keras needing to update\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer= OPTIM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 214s 5ms/step - loss: 1.7875 - val_loss: 1.4298\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 213s 5ms/step - loss: 1.3953 - val_loss: 1.2781\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 223s 6ms/step - loss: 1.2655 - val_loss: 1.1750\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 195s 5ms/step - loss: 1.1819 - val_loss: 1.1625\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 199s 5ms/step - loss: 1.1077 - val_loss: 1.1542\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 191s 5ms/step - loss: 1.0469 - val_loss: 1.0635\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 189s 5ms/step - loss: 0.9948 - val_loss: 1.0986\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 190s 5ms/step - loss: 0.9547 - val_loss: 1.0101\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 190s 5ms/step - loss: 0.9130 - val_loss: 1.0328\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 188s 5ms/step - loss: 0.8727 - val_loss: 1.0094\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 189s 5ms/step - loss: 0.8324 - val_loss: 1.1391\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 190s 5ms/step - loss: 0.8019 - val_loss: 1.0653\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 188s 5ms/step - loss: 0.7762 - val_loss: 1.0089\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 193s 5ms/step - loss: 0.7461 - val_loss: 1.0162\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 189s 5ms/step - loss: 0.7230 - val_loss: 0.9858\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 190s 5ms/step - loss: 0.7035 - val_loss: 0.9891\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 188s 5ms/step - loss: 0.6708 - val_loss: 1.0082\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 188s 5ms/step - loss: 0.6523 - val_loss: 1.0285\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 192s 5ms/step - loss: 0.6380 - val_loss: 1.0636\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 192s 5ms/step - loss: 0.6175 - val_loss: 1.0865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1cd68a3e550>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size= BATCH_SIZE, epochs= NB_EPOCH, validation_split= VALIDATION_SPLIT, verbose=VERBOSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 22s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,y_test, batch_size= BATCH_SIZE, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "###once the model has trained we can use it to predict any otheer images as long as it has the correct shape 32,32,3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
